{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from core import * \n",
    "import cupy as cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/1000, Loss: 2.0113\n",
      "Epoch 100/1000, Loss: 0.6422\n",
      "Epoch 200/1000, Loss: 0.6213\n",
      "Epoch 300/1000, Loss: 0.6086\n",
      "Epoch 400/1000, Loss: 0.6007\n",
      "Epoch 500/1000, Loss: 0.5957\n",
      "Epoch 600/1000, Loss: 0.5925\n",
      "Epoch 700/1000, Loss: 0.5904\n",
      "Epoch 800/1000, Loss: 0.5891\n",
      "Epoch 900/1000, Loss: 0.5882\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Training Setup\n",
    "x = cp.array([[1, 2, 3],\n",
    "              [4, 5, 6],\n",
    "              [7, 8, 9],\n",
    "              [10, 11, 12]])  # (4, 3)\n",
    "\n",
    "# Target labels for binary classification (simulated)\n",
    "y = cp.array([[1], [0], [1], [0]])  # (4, 1)\n",
    "\n",
    "# Create a simple feedforward network\n",
    "model = Sequential(\n",
    "    Linear(in_features=3, out_features=5, bias=True),\n",
    "    Activation(\"relu\"),\n",
    "    Linear(in_features=5, out_features=1, bias=True),  # Single output for binary classification\n",
    "    Activation(\"sigmoid\")  # Sigmoid for binary output\n",
    ")\n",
    "\n",
    "# Initialize BCE loss\n",
    "loss_fn = BCE()\n",
    "\n",
    "# Hyperparameters\n",
    "learning_rate = 0.01\n",
    "epochs = 1000\n",
    "\n",
    "# Training Loop\n",
    "for epoch in range(epochs):\n",
    "    # Forward pass\n",
    "    output = model.forward(x)\n",
    "\n",
    "    # Compute loss\n",
    "    loss = loss_fn.forward(output, y)\n",
    "\n",
    "    # Backward pass\n",
    "    upstream_grad = loss_fn.backward()  # Gradient of loss w.r.t. output\n",
    "    model.backward(upstream_grad)\n",
    "\n",
    "    # Update weights\n",
    "    model.update(learning_rate)\n",
    "\n",
    "    # Print loss for every 100 epochs\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch {epoch}/{epochs}, Loss: {loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/1000, Loss: 1.2894\n",
      "Epoch 100/1000, Loss: 0.7796\n",
      "Epoch 200/1000, Loss: 0.7526\n",
      "Epoch 300/1000, Loss: 0.7280\n",
      "Epoch 400/1000, Loss: 0.7053\n",
      "Epoch 500/1000, Loss: 0.6850\n",
      "Epoch 600/1000, Loss: 0.6685\n",
      "Epoch 700/1000, Loss: 0.6547\n",
      "Epoch 800/1000, Loss: 0.6428\n",
      "Epoch 900/1000, Loss: 0.6326\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Training Setup\n",
    "x = cp.array([[1, 2, 3],\n",
    "              [4, 5, 6],\n",
    "              [7, 8, 9],\n",
    "              [10, 11, 12]])  # (4, 3)\n",
    "\n",
    "# Target labels for binary classification (simulated)\n",
    "y = cp.array([[1], [0], [1], [0]])  # (4, 1)\n",
    "\n",
    "\n",
    "model = Sequential(\n",
    "    Linear(in_features=3, out_features=5, bias=True),\n",
    "    Activation(\"relu\"),\n",
    "    Linear(in_features=5, out_features=1, bias=True),  # Single output for binary classification\n",
    "    Activation(\"sigmoid\")  # Sigmoid for binary output\n",
    ")\n",
    "\n",
    "# Initialize BCE loss\n",
    "loss_fn = BCE()\n",
    "\n",
    "# Hyperparameters\n",
    "learning_rate = 0.001\n",
    "epochs = 1000\n",
    "\n",
    "loss = train(model=model , \n",
    "             loss_fn=loss_fn,\n",
    "             x=x,\n",
    "             y=y,\n",
    "             epochs=epochs,\n",
    "             learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape: (569, 30)\n",
      "Target shape: (569,)\n",
      "Feature names: ['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
      " 'mean smoothness' 'mean compactness' 'mean concavity'\n",
      " 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
      " 'radius error' 'texture error' 'perimeter error' 'area error'\n",
      " 'smoothness error' 'compactness error' 'concavity error'\n",
      " 'concave points error' 'symmetry error' 'fractal dimension error'\n",
      " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
      " 'worst smoothness' 'worst compactness' 'worst concavity'\n",
      " 'worst concave points' 'worst symmetry' 'worst fractal dimension']\n",
      "Target names: ['malignant' 'benign']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "# Load the dataset\n",
    "cancer_data = load_breast_cancer()\n",
    "\n",
    "# Access the data and target\n",
    "X = cancer_data.data  # Features\n",
    "y = cancer_data.target  # Target labels\n",
    "\n",
    "# Print out some details about the dataset\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "print(f\"Feature names: {cancer_data.feature_names}\")\n",
    "print(f\"Target names: {cancer_data.target_names}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/5000, Loss: 1.3010\n",
      "Epoch 100/5000, Loss: 12.8689\n",
      "Epoch 200/5000, Loss: 12.8689\n",
      "Epoch 300/5000, Loss: 12.8689\n",
      "Epoch 400/5000, Loss: 12.8689\n",
      "Epoch 500/5000, Loss: 12.8689\n",
      "Epoch 600/5000, Loss: 12.8689\n",
      "Epoch 700/5000, Loss: 12.8689\n",
      "Epoch 800/5000, Loss: 12.8689\n",
      "Epoch 900/5000, Loss: 12.8689\n",
      "Epoch 1000/5000, Loss: 12.8689\n",
      "Epoch 1100/5000, Loss: 12.8689\n",
      "Epoch 1200/5000, Loss: 12.8689\n",
      "Epoch 1300/5000, Loss: 12.8689\n",
      "Epoch 1400/5000, Loss: 12.8689\n",
      "Epoch 1500/5000, Loss: 12.8689\n",
      "Epoch 1600/5000, Loss: 12.8689\n",
      "Epoch 1700/5000, Loss: 12.8689\n",
      "Epoch 1800/5000, Loss: 12.8689\n",
      "Epoch 1900/5000, Loss: 12.8689\n",
      "Epoch 2000/5000, Loss: 12.8689\n",
      "Epoch 2100/5000, Loss: 12.8689\n",
      "Epoch 2200/5000, Loss: 12.8689\n",
      "Epoch 2300/5000, Loss: 12.8689\n",
      "Epoch 2400/5000, Loss: 12.8689\n",
      "Epoch 2500/5000, Loss: 12.8689\n",
      "Epoch 2600/5000, Loss: 12.8689\n",
      "Epoch 2700/5000, Loss: 12.8689\n",
      "Epoch 2800/5000, Loss: 12.8689\n",
      "Epoch 2900/5000, Loss: 12.8689\n",
      "Epoch 3000/5000, Loss: 12.8689\n",
      "Epoch 3100/5000, Loss: 12.8689\n",
      "Epoch 3200/5000, Loss: 12.8689\n",
      "Epoch 3300/5000, Loss: 12.8689\n",
      "Epoch 3400/5000, Loss: 12.8689\n",
      "Epoch 3500/5000, Loss: 12.8689\n",
      "Epoch 3600/5000, Loss: 12.8689\n",
      "Epoch 3700/5000, Loss: 12.8689\n",
      "Epoch 3800/5000, Loss: 12.8689\n",
      "Epoch 3900/5000, Loss: 12.8689\n",
      "Epoch 4000/5000, Loss: 12.8689\n",
      "Epoch 4100/5000, Loss: 12.8689\n",
      "Epoch 4200/5000, Loss: 12.8689\n",
      "Epoch 4300/5000, Loss: 12.8689\n",
      "Epoch 4400/5000, Loss: 12.8689\n",
      "Epoch 4500/5000, Loss: 12.8689\n",
      "Epoch 4600/5000, Loss: 12.8689\n",
      "Epoch 4700/5000, Loss: 12.8689\n",
      "Epoch 4800/5000, Loss: 12.8689\n",
      "Epoch 4900/5000, Loss: 12.8689\n"
     ]
    }
   ],
   "source": [
    "# Normalize input data\n",
    "X_mean = X.mean(axis=0)\n",
    "X_std = X.std(axis=0)\n",
    "X_normalized = (X - X_mean) / (X_std + 1e-8)\n",
    "\n",
    "# Convert to GPU arrays\n",
    "X_gpu = cp.asarray(X_normalized)\n",
    "y_gpu = cp.asarray(y)\n",
    "\n",
    "if y_gpu.ndim == 1:\n",
    "    y_gpu = y_gpu.reshape(-1, 1)\n",
    "\n",
    "# Initialize model with proper scaling\n",
    "cancer_model = Sequential(\n",
    "    Linear(in_features=X_gpu.shape[1], out_features=64, initializer='he'),\n",
    "    Activation(\"relu\"),\n",
    "    Linear(in_features=64, out_features=32, initializer='he'),\n",
    "    Activation(\"relu\"),\n",
    "    Linear(in_features=32, out_features=1, initializer='he'),\n",
    "    Activation(\"sigmoid\")\n",
    ")\n",
    "\n",
    "loss_fn = BCE()\n",
    "\n",
    "# Adjusted hyperparameters\n",
    "learning_rate = 0.1  # Increased learning rate\n",
    "epochs = 5000\n",
    "\n",
    "loss = train(model=cancer_model,\n",
    "            loss_fn=loss_fn,\n",
    "            x=X_gpu,\n",
    "            y=y_gpu,\n",
    "            epochs=epochs,\n",
    "            learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape: (569, 30)\n",
      "Target shape: (569,)\n",
      "Feature names: ['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
      " 'mean smoothness' 'mean compactness' 'mean concavity'\n",
      " 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
      " 'radius error' 'texture error' 'perimeter error' 'area error'\n",
      " 'smoothness error' 'compactness error' 'concavity error'\n",
      " 'concave points error' 'symmetry error' 'fractal dimension error'\n",
      " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
      " 'worst smoothness' 'worst compactness' 'worst concavity'\n",
      " 'worst concave points' 'worst symmetry' 'worst fractal dimension']\n",
      "Target names: ['malignant' 'benign']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "# Load the dataset\n",
    "cancer_data = load_breast_cancer()\n",
    "\n",
    "# Access the data and target\n",
    "X = cancer_data.data  # Features\n",
    "y = cancer_data.target  # Target labels\n",
    "\n",
    "# Print out some details about the dataset\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "print(f\"Feature names: {cancer_data.feature_names}\")\n",
    "print(f\"Target names: {cancer_data.target_names}\")\n",
    "\n",
    "\n",
    "# Normalize input data\n",
    "X_mean = X.mean(axis=0)\n",
    "X_std = X.std(axis=0)\n",
    "X_normalized = (X - X_mean) / (X_std + 1e-8)\n",
    "\n",
    "# Convert to GPU arrays\n",
    "X_gpu = cp.asarray(X_normalized)\n",
    "y_gpu = cp.asarray(y)\n",
    "\n",
    "if y_gpu.ndim == 1:\n",
    "    y_gpu = y_gpu.reshape(-1, 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Loss = 0.2503\n",
      "Epoch 100: Loss = 0.1816\n",
      "Epoch 200: Loss = 0.0732\n",
      "Epoch 300: Loss = 0.0450\n",
      "Epoch 400: Loss = 0.0344\n",
      "Epoch 500: Loss = 0.0287\n",
      "Epoch 600: Loss = 0.0252\n",
      "Epoch 700: Loss = 0.0229\n",
      "Epoch 800: Loss = 0.0212\n",
      "Epoch 900: Loss = 0.0199\n",
      "Epoch 1000: Loss = 0.0189\n",
      "Epoch 1100: Loss = 0.0181\n",
      "Epoch 1200: Loss = 0.0174\n",
      "Epoch 1300: Loss = 0.0168\n",
      "Epoch 1400: Loss = 0.0163\n",
      "Epoch 1500: Loss = 0.0159\n",
      "Epoch 1600: Loss = 0.0155\n",
      "Epoch 1700: Loss = 0.0152\n",
      "Epoch 1800: Loss = 0.0149\n",
      "Epoch 1900: Loss = 0.0146\n",
      "Epoch 2000: Loss = 0.0144\n",
      "Epoch 2100: Loss = 0.0142\n",
      "Epoch 2200: Loss = 0.0140\n",
      "Epoch 2300: Loss = 0.0138\n",
      "Epoch 2400: Loss = 0.0136\n",
      "Epoch 2500: Loss = 0.0134\n",
      "Epoch 2600: Loss = 0.0133\n",
      "Epoch 2700: Loss = 0.0131\n",
      "Epoch 2800: Loss = 0.0130\n",
      "Epoch 2900: Loss = 0.0129\n",
      "Epoch 3000: Loss = 0.0128\n",
      "Epoch 3100: Loss = 0.0126\n",
      "Epoch 3200: Loss = 0.0125\n",
      "Epoch 3300: Loss = 0.0124\n",
      "Epoch 3400: Loss = 0.0123\n",
      "Epoch 3500: Loss = 0.0122\n",
      "Epoch 3600: Loss = 0.0121\n",
      "Epoch 3700: Loss = 0.0120\n",
      "Epoch 3800: Loss = 0.0120\n",
      "Epoch 3900: Loss = 0.0119\n",
      "Epoch 4000: Loss = 0.0118\n",
      "Epoch 4100: Loss = 0.0117\n",
      "Epoch 4200: Loss = 0.0116\n",
      "Epoch 4300: Loss = 0.0116\n",
      "Epoch 4400: Loss = 0.0115\n",
      "Epoch 4500: Loss = 0.0114\n",
      "Epoch 4600: Loss = 0.0114\n",
      "Epoch 4700: Loss = 0.0113\n",
      "Epoch 4800: Loss = 0.0112\n",
      "Epoch 4900: Loss = 0.0112\n",
      "Epoch 5000: Loss = 0.0111\n",
      "Epoch 5100: Loss = 0.0110\n",
      "Epoch 5200: Loss = 0.0110\n",
      "Epoch 5300: Loss = 0.0109\n",
      "Epoch 5400: Loss = 0.0109\n",
      "Epoch 5500: Loss = 0.0108\n",
      "Epoch 5600: Loss = 0.0107\n",
      "Epoch 5700: Loss = 0.0107\n",
      "Epoch 5800: Loss = 0.0106\n",
      "Epoch 5900: Loss = 0.0106\n",
      "Epoch 6000: Loss = 0.0105\n",
      "Epoch 6100: Loss = 0.0105\n",
      "Epoch 6200: Loss = 0.0104\n",
      "Epoch 6300: Loss = 0.0104\n",
      "Epoch 6400: Loss = 0.0103\n",
      "Epoch 6500: Loss = 0.0103\n",
      "Epoch 6600: Loss = 0.0102\n",
      "Epoch 6700: Loss = 0.0101\n",
      "Epoch 6800: Loss = 0.0101\n",
      "Epoch 6900: Loss = 0.0100\n",
      "Epoch 7000: Loss = 0.0100\n",
      "Epoch 7100: Loss = 0.0099\n",
      "Epoch 7200: Loss = 0.0099\n",
      "Epoch 7300: Loss = 0.0098\n",
      "Epoch 7400: Loss = 0.0098\n",
      "Epoch 7500: Loss = 0.0097\n",
      "Epoch 7600: Loss = 0.0097\n",
      "Epoch 7700: Loss = 0.0096\n",
      "Epoch 7800: Loss = 0.0096\n",
      "Epoch 7900: Loss = 0.0096\n",
      "Epoch 8000: Loss = 0.0095\n",
      "Epoch 8100: Loss = 0.0095\n",
      "Epoch 8200: Loss = 0.0094\n",
      "Epoch 8300: Loss = 0.0094\n",
      "Epoch 8400: Loss = 0.0093\n",
      "Epoch 8500: Loss = 0.0093\n",
      "Epoch 8600: Loss = 0.0092\n",
      "Epoch 8700: Loss = 0.0092\n",
      "Epoch 8800: Loss = 0.0091\n",
      "Epoch 8900: Loss = 0.0091\n",
      "Epoch 9000: Loss = 0.0091\n",
      "Epoch 9100: Loss = 0.0090\n",
      "Epoch 9200: Loss = 0.0090\n",
      "Epoch 9300: Loss = 0.0089\n",
      "Epoch 9400: Loss = 0.0089\n",
      "Epoch 9500: Loss = 0.0088\n",
      "Epoch 9600: Loss = 0.0088\n",
      "Epoch 9700: Loss = 0.0088\n",
      "Epoch 9800: Loss = 0.0087\n",
      "Epoch 9900: Loss = 0.0087\n",
      "Epoch 10000: Loss = 0.0086\n",
      "Epoch 10100: Loss = 0.0086\n",
      "Epoch 10200: Loss = 0.0085\n",
      "Epoch 10300: Loss = 0.0085\n",
      "Epoch 10400: Loss = 0.0085\n",
      "Epoch 10500: Loss = 0.0084\n",
      "Epoch 10600: Loss = 0.0084\n",
      "Epoch 10700: Loss = 0.0083\n",
      "Epoch 10800: Loss = 0.0083\n",
      "Epoch 10900: Loss = 0.0083\n",
      "Epoch 11000: Loss = 0.0082\n",
      "Epoch 11100: Loss = 0.0082\n",
      "Epoch 11200: Loss = 0.0081\n",
      "Epoch 11300: Loss = 0.0081\n",
      "Epoch 11400: Loss = 0.0081\n",
      "Epoch 11500: Loss = 0.0080\n",
      "Epoch 11600: Loss = 0.0080\n",
      "Epoch 11700: Loss = 0.0080\n",
      "Epoch 11800: Loss = 0.0079\n",
      "Epoch 11900: Loss = 0.0079\n",
      "Epoch 12000: Loss = 0.0079\n",
      "Epoch 12100: Loss = 0.0078\n",
      "Epoch 12200: Loss = 0.0078\n",
      "Epoch 12300: Loss = 0.0078\n",
      "Epoch 12400: Loss = 0.0077\n",
      "Epoch 12500: Loss = 0.0077\n",
      "Epoch 12600: Loss = 0.0077\n",
      "Epoch 12700: Loss = 0.0076\n",
      "Epoch 12800: Loss = 0.0076\n",
      "Epoch 12900: Loss = 0.0076\n",
      "Epoch 13000: Loss = 0.0076\n",
      "Epoch 13100: Loss = 0.0075\n",
      "Epoch 13200: Loss = 0.0075\n",
      "Epoch 13300: Loss = 0.0075\n",
      "Epoch 13400: Loss = 0.0074\n",
      "Epoch 13500: Loss = 0.0074\n",
      "Epoch 13600: Loss = 0.0074\n",
      "Epoch 13700: Loss = 0.0073\n",
      "Epoch 13800: Loss = 0.0073\n",
      "Epoch 13900: Loss = 0.0073\n",
      "Epoch 14000: Loss = 0.0073\n",
      "Epoch 14100: Loss = 0.0072\n",
      "Epoch 14200: Loss = 0.0072\n",
      "Epoch 14300: Loss = 0.0072\n",
      "Epoch 14400: Loss = 0.0071\n",
      "Epoch 14500: Loss = 0.0071\n",
      "Epoch 14600: Loss = 0.0071\n",
      "Epoch 14700: Loss = 0.0071\n",
      "Epoch 14800: Loss = 0.0070\n",
      "Epoch 14900: Loss = 0.0070\n",
      "Epoch 15000: Loss = 0.0070\n",
      "Epoch 15100: Loss = 0.0070\n",
      "Epoch 15200: Loss = 0.0070\n",
      "Epoch 15300: Loss = 0.0069\n",
      "Epoch 15400: Loss = 0.0069\n",
      "Epoch 15500: Loss = 0.0069\n",
      "Epoch 15600: Loss = 0.0069\n",
      "Epoch 15700: Loss = 0.0068\n",
      "Epoch 15800: Loss = 0.0068\n",
      "Epoch 15900: Loss = 0.0068\n",
      "Epoch 16000: Loss = 0.0068\n",
      "Epoch 16100: Loss = 0.0067\n",
      "Epoch 16200: Loss = 0.0067\n",
      "Epoch 16300: Loss = 0.0067\n",
      "Epoch 16400: Loss = 0.0067\n",
      "Epoch 16500: Loss = 0.0067\n",
      "Epoch 16600: Loss = 0.0066\n",
      "Epoch 16700: Loss = 0.0066\n",
      "Epoch 16800: Loss = 0.0066\n",
      "Epoch 16900: Loss = 0.0066\n",
      "Epoch 17000: Loss = 0.0066\n",
      "Epoch 17100: Loss = 0.0065\n",
      "Epoch 17200: Loss = 0.0065\n",
      "Epoch 17300: Loss = 0.0065\n",
      "Epoch 17400: Loss = 0.0065\n",
      "Epoch 17500: Loss = 0.0065\n",
      "Epoch 17600: Loss = 0.0064\n",
      "Epoch 17700: Loss = 0.0064\n",
      "Epoch 17800: Loss = 0.0064\n",
      "Epoch 17900: Loss = 0.0064\n",
      "Epoch 18000: Loss = 0.0064\n",
      "Epoch 18100: Loss = 0.0063\n",
      "Epoch 18200: Loss = 0.0063\n",
      "Epoch 18300: Loss = 0.0063\n",
      "Epoch 18400: Loss = 0.0063\n",
      "Epoch 18500: Loss = 0.0063\n",
      "Epoch 18600: Loss = 0.0063\n",
      "Epoch 18700: Loss = 0.0062\n",
      "Epoch 18800: Loss = 0.0062\n",
      "Epoch 18900: Loss = 0.0062\n",
      "Epoch 19000: Loss = 0.0062\n",
      "Epoch 19100: Loss = 0.0062\n",
      "Epoch 19200: Loss = 0.0062\n",
      "Epoch 19300: Loss = 0.0061\n",
      "Epoch 19400: Loss = 0.0061\n",
      "Epoch 19500: Loss = 0.0061\n",
      "Epoch 19600: Loss = 0.0061\n",
      "Epoch 19700: Loss = 0.0061\n",
      "Epoch 19800: Loss = 0.0061\n",
      "Epoch 19900: Loss = 0.0060\n"
     ]
    }
   ],
   "source": [
    "from simple import NeuralNetwork \n",
    "\n",
    "# Define network with 3 layers: input (2), hidden (3), output (1)\n",
    "layers = [X_gpu.shape[1] , 128  ,  1]\n",
    "\n",
    "activation_functions = ['relu',  'sigmoid' ]\n",
    "\n",
    "nn = NeuralNetwork(layers, activation_functions, learning_rate=0.1) \n",
    "\n",
    "\n",
    "    # Train the network\n",
    "loss_history = nn.train(X_gpu, y_gpu, epochs=20000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape: (1797, 64)\n",
      "Target shape: (1797,)\n",
      "Feature names: ['pixel_0_0', 'pixel_0_1', 'pixel_0_2', 'pixel_0_3', 'pixel_0_4', 'pixel_0_5', 'pixel_0_6', 'pixel_0_7', 'pixel_1_0', 'pixel_1_1', 'pixel_1_2', 'pixel_1_3', 'pixel_1_4', 'pixel_1_5', 'pixel_1_6', 'pixel_1_7', 'pixel_2_0', 'pixel_2_1', 'pixel_2_2', 'pixel_2_3', 'pixel_2_4', 'pixel_2_5', 'pixel_2_6', 'pixel_2_7', 'pixel_3_0', 'pixel_3_1', 'pixel_3_2', 'pixel_3_3', 'pixel_3_4', 'pixel_3_5', 'pixel_3_6', 'pixel_3_7', 'pixel_4_0', 'pixel_4_1', 'pixel_4_2', 'pixel_4_3', 'pixel_4_4', 'pixel_4_5', 'pixel_4_6', 'pixel_4_7', 'pixel_5_0', 'pixel_5_1', 'pixel_5_2', 'pixel_5_3', 'pixel_5_4', 'pixel_5_5', 'pixel_5_6', 'pixel_5_7', 'pixel_6_0', 'pixel_6_1', 'pixel_6_2', 'pixel_6_3', 'pixel_6_4', 'pixel_6_5', 'pixel_6_6', 'pixel_6_7', 'pixel_7_0', 'pixel_7_1', 'pixel_7_2', 'pixel_7_3', 'pixel_7_4', 'pixel_7_5', 'pixel_7_6', 'pixel_7_7']\n",
      "Target names: [0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits \n",
    "\n",
    "# Load the dataset\n",
    "digits_data = load_digits()\n",
    "\n",
    "# Access the data and target\n",
    "X = digits_data.data  # Features\n",
    "y = digits_data.target  # Target labels\n",
    "\n",
    "# Print out some details about the dataset\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "print(f\"Feature names: {digits_data.feature_names}\")\n",
    "print(f\"Target names: {digits_data.target_names}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mean = X.mean(axis=0)\n",
    "X_std = X.std(axis=0)\n",
    "X_normalized = (X - X_mean) / (X_std + 1e-8)\n",
    "\n",
    "# Convert to GPU arrays\n",
    "X_gpu = cp.asarray(X_normalized)\n",
    "y_gpu = cp.asarray(y)\n",
    "\n",
    "if y_gpu.ndim == 1:\n",
    "    y_gpu = y_gpu.reshape(-1, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Axis dimension mismatch",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[145], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m activation_functions \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msigmoid\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      9\u001b[0m nn \u001b[38;5;241m=\u001b[39m NeuralNetwork(layers, activation_functions, learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m)\n\u001b[0;32m---> 10\u001b[0m loss_history \u001b[38;5;241m=\u001b[39m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_gpu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_gpu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5000\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/SILVA.AI/Projects/SilvaXNet/notebook/simple.py:108\u001b[0m, in \u001b[0;36mNeuralNetwork.train\u001b[0;34m(self, X, y, epochs)\u001b[0m\n\u001b[1;32m    105\u001b[0m loss \u001b[38;5;241m=\u001b[39m cp\u001b[38;5;241m.\u001b[39mmean((output \u001b[38;5;241m-\u001b[39m y) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m)  \u001b[38;5;66;03m# Mean Squared Error loss\u001b[39;00m\n\u001b[1;32m    106\u001b[0m loss_history\u001b[38;5;241m.\u001b[39mappend(loss)\n\u001b[0;32m--> 108\u001b[0m grads \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_parameters(grads)\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/SILVA.AI/Projects/SilvaXNet/notebook/simple.py:85\u001b[0m, in \u001b[0;36mNeuralNetwork.backward\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     83\u001b[0m     grads[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdW\u001b[39m\u001b[38;5;132;01m{\u001b[39;00ml\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m cp\u001b[38;5;241m.\u001b[39mdot(A_prev\u001b[38;5;241m.\u001b[39mT, dZ)\n\u001b[1;32m     84\u001b[0m     grads[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdb\u001b[39m\u001b[38;5;132;01m{\u001b[39;00ml\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m cp\u001b[38;5;241m.\u001b[39msum(dZ, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 85\u001b[0m     dA \u001b[38;5;241m=\u001b[39m \u001b[43mcp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdZ\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweights\u001b[49m\u001b[43m[\u001b[49m\u001b[43ml\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m grads\n",
      "File \u001b[0;32m~/anaconda3/envs/SilvaXnet_cuda11/lib/python3.10/site-packages/cupy/linalg/_product.py:63\u001b[0m, in \u001b[0;36mdot\u001b[0;34m(a, b, out)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns a dot product of two arrays.\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \n\u001b[1;32m     46\u001b[0m \u001b[38;5;124;03mFor arrays with more than one axis, it computes the dot product along the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     60\u001b[0m \n\u001b[1;32m     61\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m# TODO(okuta): check type\u001b[39;00m\n\u001b[0;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32mcupy/_core/core.pyx:1763\u001b[0m, in \u001b[0;36mcupy._core.core._ndarray_base.dot\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mcupy/_core/_routines_linalg.pyx:510\u001b[0m, in \u001b[0;36mcupy._core._routines_linalg.dot\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Axis dimension mismatch"
     ]
    }
   ],
   "source": [
    "# In your notebook\n",
    "X_gpu = cp.asarray(X_normalized)\n",
    "y_gpu = cp.asarray(y)\n",
    "\n",
    "# For binary classification\n",
    "layers = [X_gpu.shape[1], 64, 32, 1]\n",
    "activation_functions = ['relu', 'relu', 'sigmoid']\n",
    "\n",
    "nn = NeuralNetwork(layers, activation_functions, learning_rate=0.01)\n",
    "loss_history = nn.train(X_gpu, y_gpu, epochs=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SilvaXnet_cuda11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
